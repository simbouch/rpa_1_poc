# ğŸ§  Prototype IA â€“ Extraction de donnÃ©es depuis des documents PDF

Ce projet propose une application web interactive pour extraire automatiquement des informations clÃ©s depuis des rapports PDF Ã  lâ€™aide de techniques de traitement automatique du langage (NLP). Lâ€™outil sâ€™appuie sur des modÃ¨les spaCy personnalisÃ©s ou prÃ©-entraÃ®nÃ©s, et offre une interface simple grÃ¢ce Ã  Streamlit.

---

## ğŸš€ FonctionnalitÃ©s principales

- **SÃ©lection du modÃ¨le dâ€™extraction**  
  â€¢ Choix entre le modÃ¨le spaCy par dÃ©faut (`fr_core_news_md`) ou un modÃ¨le personnalisÃ© entraÃ®nÃ© (prÃ©sent dans `training/model_output/model-best`).  
  â€¢ Affichage des informations (version, date de crÃ©ation) du modÃ¨le personnalisÃ© lorsquâ€™il est reconnu.

- **Extraction structurÃ©e des champs suivants**  
  â€¢ Nom et prÃ©nom de la personne  
  â€¢ RÃ©fÃ©rence de dossier  
  â€¢ Type dâ€™analyse ou de prÃ©lÃ¨vement  
  â€¢ Date de prÃ©lÃ¨vement  
  â€¢ Service demandeur  

- **Affichage et tÃ©lÃ©chargement des rÃ©sultats**  
  â€¢ AperÃ§u des champs extraits avec indicateurs de rÃ©ussite/absence (âœ”/âš ).  
  â€¢ TÃ©lÃ©chargement des rÃ©sultats au format JSON et CSV.  
  â€¢ Option dâ€™afficher des mÃ©tadonnÃ©es techniques (mÃ©thode dâ€™extraction, nombre de champs dÃ©tectÃ©s, longueur du texte).

- **Traitement de fichiers PDF multipages**  
  â€¢ Lecture de tout le contenu dâ€™un PDF via `pdfplumber`.  
  â€¢ Passage automatique du texte au pipeline spaCy pour la dÃ©tection dâ€™entitÃ©s nommÃ©es.

- **Interface ergonomique**  
  â€¢ Barre latÃ©rale pour la configuration (sÃ©lection de modÃ¨le, affichage de mÃ©tadonnÃ©es/options).  
  â€¢ Colonnes dynamiques pour lâ€™upload, la visualisation des champs et le tÃ©lÃ©chargement.  
  â€¢ Indicateurs de temps de traitement.

---

## ğŸ—ï¸ Architecture du projet

rpa_1_poc/
â”œâ”€â”€ app.py # Point dâ€™entrÃ©e Streamlit
â”œâ”€â”€ extraction_enhanced.py # Classe PDFExtractor et utilitaires
â”œâ”€â”€ requirements.txt # DÃ©pendances Python
â”œâ”€â”€ README.md # Documentation (ce fichier)
â”‚
â”œâ”€â”€ training/ # EntraÃ®nement et modÃ¨les spaCy NER
â”‚ â”œâ”€â”€ data/
â”‚ â”‚ â”œâ”€â”€ raw/ # Rapports PDF bruts Ã  annoter
â”‚ â”‚ â””â”€â”€ spacy_format/
â”‚ â”‚ â”œâ”€â”€ train_data.json # Exemple de donnÃ©es annotÃ©es
â”‚ â”‚ â””â”€â”€ train_data.spacy # Fichier binaire spaCy pour entraÃ®nement
â”‚ â”œâ”€â”€ config.cfg # Configuration du pipeline spaCy (NER)
â”‚ â”œâ”€â”€ train.py # Script pour lancer lâ€™entraÃ®nement
â”‚ â””â”€â”€ model_output/
â”‚ â””â”€â”€ model-best/ # RÃ©pertoire contenant le modÃ¨le entraÃ®nÃ©
â”‚
â”œâ”€â”€ data/ # Dossier facultatif pour exemples PDF
â””â”€â”€ venv/ # Environnement virtuel (optionnel)

markdown
Copy
Edit

- **app.py** :  
  - GÃ¨re lâ€™interface Streamlit (chargement de modÃ¨le, upload PDF, affichage des rÃ©sultats, tÃ©lÃ©chargement).  
  - DÃ©finit la configuration de la page, la sidebar et les colonnes principales.  
- **extraction_enhanced.py** :  
  - Contient la classe `PDFExtractor`, qui encapsule la logique dâ€™extraction : lecture PDF, prÃ©traitement, passage au modÃ¨le spaCy, calcul des mÃ©tadonnÃ©es, etc.  
  - La fonction `get_available_models()` liste les chemins des dossiers de modÃ¨les valides (modÃ¨le personnalisÃ© ou `fr_core_news_md`).  
- **training/** :  
  - Permet de fine-tuner un modÃ¨le NER spaCy pour dÃ©tecter spÃ©cifiquement les entitÃ©s (nom_personne, reference_dossier, type_analyse, date_prelevement, service_demandeur).  
  - Le fichier `train_data.json` regroupe les exemples annotÃ©s, et `train_data.spacy` est le format binaire gÃ©nÃ©rÃ© par `python -m spacy convert`.  
  - `config.cfg` dÃ©finit le pipeline spaCy (tok2vec â†’ ner) et les hyperparamÃ¨tres dâ€™entraÃ®nement (seed, dropout, max_epochs, etc.).  
  - `train.py` exÃ©cute la commande `spacy train training/config.cfg --output training/model_output`.  
  - AprÃ¨s lâ€™entraÃ®nement, le modÃ¨le final se trouve dans `training/model_output/model-best`.

---

## âš™ï¸ Installation

1. **Cloner le dÃ©pÃ´t**  
   ```bash
   git clone https://github.com/simbouch/rpa_1_poc
   cd rpa_1_poc
CrÃ©er et activer un environnement virtuel

bash
Copy
Edit
python -m venv venv
# Sous PowerShell (Windows) :
.\venv\Scripts\Activate.ps1
# Sous macOS/Linux :
source venv/bin/activate
Installer les dÃ©pendances

bash
Copy
Edit
pip install -r requirements.txt
TÃ©lÃ©charger le modÃ¨le spaCy franÃ§ais (si nÃ©cessaire)

Si fr_core_news_md nâ€™est pas dÃ©jÃ  installÃ© via requirements.txt, exÃ©cute :

bash
Copy
Edit
python -m spacy download fr_core_news_md
ğŸ“¦ Lancer lâ€™application
Une fois lâ€™environnement activÃ© et les dÃ©pendances installÃ©es, lance simplement :

bash
Copy
Edit
streamlit run app.py
Le navigateur sâ€™ouvrira automatiquement sur http://localhost:8501/.

Dans la barre latÃ©rale, sÃ©lectionne le modÃ¨le Ã  utiliser et configure les options dâ€™affichage (mÃ©tadonnÃ©es, scores de confiance).

Dans la zone principale, tÃ©lÃ©charge un fichier PDF Ã  analyser et consulte les rÃ©sultats.

ğŸ§ª Exemples dâ€™utilisation
SÃ©lectionner un modÃ¨le

Par dÃ©faut, lâ€™application propose le modÃ¨le spaCy fr_core_news_md.

Si tu as dÃ©jÃ  exÃ©cutÃ© un entraÃ®nement spaCy dans training/model_output/model-best, tu verras apparaÃ®tre â€œğŸ¯ ModÃ¨le entraÃ®nÃ© (recommandÃ©)â€.

Uploader un rapport PDF

Clique sur â€œTÃ©lÃ©charger un rapport PDFâ€ et choisis un fichier PDF.

Lâ€™application extrait automatiquement le texte du PDF et passe les donnÃ©es au pipeline NER spaCy.

Consulter les rÃ©sultats

Les champs extraits sâ€™affichent dans la colonne â€œChamps extraitsâ€. Chaque champ valide sâ€™accompagne dâ€™une coche verte (âœ”), sinon dâ€™une alerte jaune (âš ).

Le temps de traitement (en secondes) sâ€™affiche sous le titre â€œExtraction rÃ©ussie en X.XX secondesâ€.

TÃ©lÃ©charger les donnÃ©es

Dans â€œExport des donnÃ©esâ€, clique sur â€œTÃ©lÃ©charger en JSONâ€ pour obtenir un fichier .json contenant les champs extraits.

Clique sur â€œTÃ©lÃ©charger en CSVâ€ pour obtenir un fichier .csv au format :

rust
Copy
Edit
nom_prenom,BERNARD MICHEL
reference_dossier,2025-GEND/99-X
type_prelevement,Analyse toxicologique sur cheveux
date_prelevement,05/05/2025
service_demandeur,Service rÃ©gional d'investigation
Afficher les mÃ©tadonnÃ©es

Si lâ€™option â€œAfficher les mÃ©tadonnÃ©esâ€ est cochÃ©e, la section â€œMÃ©tadonnÃ©es techniquesâ€ affiche :

MÃ©thode dâ€™extraction (IA ou regex mixte)

Nombre de champs dÃ©tectÃ©s par modÃ¨le

Nombre de champs dÃ©tectÃ©s par regex

Longueur du texte source (en caractÃ¨res)

ğŸ“š EntraÃ®nement du modÃ¨le spaCy NER (optionnel)
Si tu souhaites amÃ©liorer ou adapter le modÃ¨le personnalisÃ©, suis ces Ã©tapes :

PrÃ©parer des exemples annotÃ©s

Place tes rapports PDF dans training/data/raw/.

Extrait manuellement le texte ou utilise pdfplumber pour obtenir le contenu brut.

CrÃ©e un fichier JSON train_data.json dans training/data/spacy_format/, au format spaCy :

json
Copy
Edit
[
  [
    "Nom : DUPOND JEAN\nRÃ©fÃ©rence : 2025-XYZ/01\nObjet : Analyse sanguine\nDate : 10/06/2025\nDemandeur : Service A",
    {
      "entities": [
        [6, 16, "nom_personne"],
        [28, 38, "reference_dossier"],
        [48, 63, "type_analyse"],
        [71, 81, "date_prelevement"],
        [93, 102, "service_demandeur"]
      ]
    }
  ],
  ...
]
Copie/colle ce JSON dans training/data/spacy_format/train_data.json.

Convertir le JSON en .spacy

bash
Copy
Edit
python -m spacy convert training/data/spacy_format/train_data.json training/data/spacy_format --lang fr
â†’ GÃ©nÃ¨re train_data.spacy.

Modifier (ou vÃ©rifier) training/config.cfg

Assure-toi que la clÃ© seed contient bien un entier (ex. seed = 42).

VÃ©rifie que gpu_allocator et gpu_id sont sous [training].

Si tu souhaites un jeu de validation, crÃ©e un fichier dev_data.json en suivant la mÃªme structure, puis exÃ©cute la conversion pour obtenir dev_data.spacy et renseigne dev = "training/data/spacy_format/dev_data.spacy".

Lancer lâ€™entraÃ®nement

bash
Copy
Edit
python training/train.py
â†’ Le modÃ¨le final se trouvera dans training/model_output/model-best/.

Tester le modÃ¨le

python
Copy
Edit
import spacy

nlp = spacy.load("training/model_output/model-best")
doc = nlp("Nom : LEROY PAUL\nRÃ©fÃ©rence : 2025-ABC/99\nObjet : Analyse urinaire\nDate : 12/06/2025\nDemandeur : Service B")
for ent in doc.ents:
    print(ent.text, ent.label_)
â†’ Devrait lister les entitÃ©s nom_personne, reference_dossier, etc.

ğŸ“„ Licence
Ce projet est sous licence **MIT
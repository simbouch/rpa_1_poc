#!/usr/bin/env python3
"""
Script d'entra√Ænement simple et direct pour le mod√®le NER.
"""

import spacy
from spacy.training import Example
from spacy.util import minibatch
import random
import json
from pathlib import Path

def load_training_data():
    """Charge les donn√©es d'entra√Ænement."""
    with open("training/data/spacy_format/train_data.json", "r", encoding="utf-8") as f:
        data = json.load(f)
    
    print(f"‚úÖ Charg√© {len(data)} exemples d'entra√Ænement")
    return data

def create_examples(nlp, data):
    """Cr√©e des exemples spaCy √† partir des donn√©es JSON."""
    examples = []
    
    for text, annotations in data:
        doc = nlp.make_doc(text)
        entities = annotations["entities"]
        
        # Filtrer les entit√©s valides
        valid_entities = []
        for start, end, label in entities:
            if start < end and end <= len(text):
                valid_entities.append((start, end, label))
        
        if valid_entities:
            example = Example.from_dict(doc, {"entities": valid_entities})
            examples.append(example)
    
    print(f"‚úÖ Cr√©√© {len(examples)} exemples valides")
    return examples

def train_model():
    """Entra√Æne le mod√®le NER."""
    print("üöÄ D√©marrage de l'entra√Ænement simple")
    
    # Charger le mod√®le de base
    nlp = spacy.load("fr_core_news_md")
    
    # Ajouter le composant NER s'il n'existe pas
    if "ner" not in nlp.pipe_names:
        ner = nlp.add_pipe("ner")
    else:
        ner = nlp.get_pipe("ner")
    
    # Charger les donn√©es
    data = load_training_data()
    
    # Ajouter les labels
    labels = ["nom_personne", "reference_dossier", "type_analyse", "date_prelevement", "service_demandeur"]
    for label in labels:
        ner.add_label(label)
    
    # Cr√©er les exemples
    examples = create_examples(nlp, data)
    
    # Diviser en train/dev
    random.shuffle(examples)
    split_idx = int(len(examples) * 0.8)
    train_examples = examples[:split_idx]
    dev_examples = examples[split_idx:]
    
    print(f"üìä Division: {len(train_examples)} entra√Ænement, {len(dev_examples)} validation")
    
    # D√©sactiver les autres composants pendant l'entra√Ænement
    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != "ner"]
    
    # Entra√Ænement
    print("üîÑ D√©but de l'entra√Ænement...")
    
    with nlp.disable_pipes(*other_pipes):
        optimizer = nlp.begin_training()
        
        for epoch in range(50):  # 50 √©poques
            print(f"√âpoque {epoch + 1}/50")
            
            # M√©langer les donn√©es
            random.shuffle(train_examples)
            losses = {}
            
            # Entra√Ænement par mini-batches
            for batch in minibatch(train_examples, size=8):
                nlp.update(batch, drop=0.2, losses=losses, sgd=optimizer)
            
            # √âvaluation tous les 10 √©poques
            if (epoch + 1) % 10 == 0:
                print(f"  Perte NER: {losses.get('ner', 0):.2f}")
                
                # √âvaluation simple
                correct = 0
                total = 0
                
                for example in dev_examples[:20]:  # Tester sur 20 exemples
                    doc = nlp(example.reference.text)
                    predicted_entities = [(ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]
                    gold_entities = [(ent.start_char, ent.end_char, ent.label_) for ent in example.reference.ents]
                    
                    for pred_ent in predicted_entities:
                        if pred_ent in gold_entities:
                            correct += 1
                    total += len(gold_entities)
                
                accuracy = correct / total if total > 0 else 0
                print(f"  Pr√©cision: {accuracy:.2f} ({correct}/{total})")
    
    # Sauvegarder le mod√®le
    output_dir = Path("training/model_output/model-best")
    output_dir.mkdir(parents=True, exist_ok=True)
    nlp.to_disk(output_dir)
    
    print(f"‚úÖ Mod√®le sauvegard√© dans {output_dir}")
    
    # Test final
    print("\nüß™ Test final du mod√®le:")
    test_texts = [
        "Nom : MARTIN JEAN\nR√©f√©rence : 2025-TEST/01-A\nObjet : Test d'analyse\nDate : 15/06/2025\nDemandeur : Service test",
        "Patient : DURAND MARIE\nDossier : 2025-LAB/02-B\nAnalyse : Examen sanguin\nPr√©l√®vement : 20/06/2025\nService : Laboratoire"
    ]
    
    for i, text in enumerate(test_texts):
        print(f"\nTest {i+1}:")
        doc = nlp(text)
        print(f"Texte: {text[:50]}...")
        print(f"Entit√©s trouv√©es: {len(doc.ents)}")
        for ent in doc.ents:
            print(f"  - {ent.label_}: '{ent.text}'")

if __name__ == "__main__":
    train_model()
